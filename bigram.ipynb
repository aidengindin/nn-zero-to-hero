{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training set of bigrams (x, y)\n",
    "\n",
    "xs, ys = [], []\n",
    "num_bigrams = 0\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        num_bigrams += 1\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F # type: ignore\n",
    "\n",
    "# initialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.184269428253174\n",
      "3.1808712482452393\n",
      "3.1775028705596924\n",
      "3.1741647720336914\n",
      "3.1708550453186035\n",
      "3.167574405670166\n",
      "3.1643218994140625\n",
      "3.161098003387451\n",
      "3.1579015254974365\n",
      "3.1547322273254395\n",
      "3.151589870452881\n",
      "3.148474931716919\n",
      "3.1453857421875\n",
      "3.142322540283203\n",
      "3.1392853260040283\n",
      "3.13627290725708\n",
      "3.1332857608795166\n",
      "3.130323886871338\n",
      "3.1273860931396484\n",
      "3.12447190284729\n",
      "3.121581792831421\n",
      "3.1187150478363037\n",
      "3.1158714294433594\n",
      "3.113051176071167\n",
      "3.1102535724639893\n",
      "3.107478380203247\n",
      "3.104724884033203\n",
      "3.1019933223724365\n",
      "3.099283456802368\n",
      "3.096595048904419\n",
      "3.0939269065856934\n",
      "3.091279983520508\n",
      "3.088653802871704\n",
      "3.086047649383545\n",
      "3.0834615230560303\n",
      "3.0808956623077393\n",
      "3.0783488750457764\n",
      "3.0758213996887207\n",
      "3.0733134746551514\n",
      "3.070824146270752\n",
      "3.0683536529541016\n",
      "3.065901517868042\n",
      "3.063467502593994\n",
      "3.061051607131958\n",
      "3.0586540699005127\n",
      "3.0562734603881836\n",
      "3.053910732269287\n",
      "3.051565647125244\n",
      "3.04923677444458\n",
      "3.0469253063201904\n",
      "3.0446300506591797\n",
      "3.0423519611358643\n",
      "3.0400900840759277\n",
      "3.037843942642212\n",
      "3.035614252090454\n",
      "3.033400297164917\n",
      "3.0312020778656006\n",
      "3.0290186405181885\n",
      "3.0268514156341553\n",
      "3.0246987342834473\n",
      "3.022561550140381\n",
      "3.0204389095306396\n",
      "3.018331289291382\n",
      "3.01623797416687\n",
      "3.0141589641571045\n",
      "3.012094497680664\n",
      "3.0100440979003906\n",
      "3.008007764816284\n",
      "3.0059852600097656\n",
      "3.0039761066436768\n",
      "3.0019805431365967\n",
      "2.9999988079071045\n",
      "2.998030424118042\n",
      "2.99607515335083\n",
      "2.9941327571868896\n",
      "2.9922032356262207\n",
      "2.9902865886688232\n",
      "2.9883828163146973\n",
      "2.9864914417266846\n",
      "2.984612464904785\n",
      "2.982745885848999\n",
      "2.980891466140747\n",
      "2.97904896736145\n",
      "2.9772188663482666\n",
      "2.975400686264038\n",
      "2.9735939502716064\n",
      "2.9717986583709717\n",
      "2.970015287399292\n",
      "2.96824312210083\n",
      "2.966482639312744\n",
      "2.964733362197876\n",
      "2.9629952907562256\n",
      "2.9612677097320557\n",
      "2.9595515727996826\n",
      "2.957846164703369\n",
      "2.9561514854431152\n",
      "2.954467535018921\n",
      "2.952793836593628\n",
      "2.9511308670043945\n",
      "2.9494786262512207\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # type: ignore\n",
    "    logits = xenc @ W  # predict log-counts\n",
    "    counts = logits.exp()  # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdim=True)  # probabilities for next character\n",
    "    loss = -probs[torch.arange(num_bigrams), ys].log().mean()  # + 0.01 * (W**2).mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -1 * W.grad # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dayti.\n",
      "kotjasihqzqrzw.\n",
      "eie.\n",
      "ke.\n",
      "zw.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdim=True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix]) # type: ignore\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join(out))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
